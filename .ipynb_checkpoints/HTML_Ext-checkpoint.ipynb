{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f5d7e73-ac51-4b80-877d-7dfb984a8966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame preview:\n",
      "           Patient                                   Location         DOB  \\\n",
      "0  YVETTE A. LOPEZ  GYN-Medical Center San Antonio (Inactive)  09/16/1963   \n",
      "1  YVETTE A. LOPEZ  GYN-Medical Center San Antonio (Inactive)  09/16/1963   \n",
      "\n",
      "          Attending Physician       MRN        Date Reasons for Visit  \\\n",
      "0  Antonio Santillan-Gomez MD  02008593  06/28/2016  FLWP ( 4 MO FU )   \n",
      "1  Antonio Santillan-Gomez MD  02008593  10/06/2016        Data entry   \n",
      "\n",
      "                          Allergies as of Visit Date  \\\n",
      "0  Vicodin, po solid (hydrocodone/acetaminophen),...   \n",
      "1  Vicodin, po solid (hydrocodone/acetaminophen),...   \n",
      "\n",
      "                              Special Considerations  \\\n",
      "0  Varicella status: Chicken pox: yes, Varicella ...   \n",
      "1  Varicella status: Chicken pox: yes, Varicella ...   \n",
      "\n",
      "                                              GYN Dx  \\\n",
      "0  Primary gyn diagnosis for this visit: Endometr...   \n",
      "1                                          Not Found   \n",
      "\n",
      "                                   Hem/Onc Diagnosis  \\\n",
      "0  Endometrial cancer: Office note: CHIEF COMPLAI...   \n",
      "1  Endometrial cancer: Office note: CHIEF COMPLAI...   \n",
      "\n",
      "                                                 H&P  \\\n",
      "0  Preventive care & screening: Tobacco history: ...   \n",
      "1  Preventive care & screening: Tobacco history: ...   \n",
      "\n",
      "                                               Signs  \\\n",
      "0  Vital signs: Blood pressure: 139/92 [Selina Sa...   \n",
      "1  Vital signs: Blood pressure: 110/82 [Veronica ...   \n",
      "\n",
      "                                          Laboratory  \\\n",
      "0  Panels: CBC w/ auto diff, CMP, CA 125: Prior t...   \n",
      "1  Microbiology: Urine culture & sensitivity: Tod...   \n",
      "\n",
      "                                          Outside Rx  \\\n",
      "0  Alavert (loratadine): Outside Rx:  10 mg Table...   \n",
      "1  Alavert (loratadine): Outside Rx:  10 mg Table...   \n",
      "\n",
      "                                         Medications  \\\n",
      "0  Medication review: ss. [Selina Saldivar, MA Sr...   \n",
      "1  Medication review: vt. [Veronica Trejo, MA, [3...   \n",
      "\n",
      "                                        Therapy note  \\\n",
      "0  MA Intake Note: no change in appetite; no fati...   \n",
      "1                                          Not Found   \n",
      "\n",
      "                                  Diagnostic Imaging  \\\n",
      "0  Ultrasound: Prior to next visit, Print on Rx.,...   \n",
      "1                                          Not Found   \n",
      "\n",
      "                                                Plan  \\\n",
      "0  Schedule return to MD: 4 months, Print on Rx. ...   \n",
      "1  Schedule return to MD: 4 months, Print on Rx. ...   \n",
      "\n",
      "                                           Text Note  \n",
      "0  Care transition-inbound: Reconciliation perfor...  \n",
      "1  Care transition-inbound: Reconciliation perfor...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    " \n",
    "# Directory containing the files\n",
    "directory_path = \"D:/HTML_Files_Ext\"\n",
    " \n",
    "# List to store data from each HTML file\n",
    "data_list = []\n",
    " \n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    # Check if the file has an .html extension\n",
    "    if filename.endswith(\".html\"):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        # Load and parse the HTML file\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            html_content = file.read()\n",
    "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "        # Extract required fields\n",
    "        patient = soup.find(\"div\", id=\"patName\").get_text(strip=True).replace(\"Patient: \", \"\")\n",
    "        location = soup.find(\"span\", id=\"locNameVal\").get_text(strip=True)\n",
    "        dob = soup.find(\"span\", id=\"dobVal\").get_text(strip=True)\n",
    "        attending_physician = soup.find(\"span\", id=\"attendingVal\").get_text(strip=True)\n",
    "        mrn = soup.find(\"span\", id=\"mrnVal\").get_text(strip=True)\n",
    "        date = soup.find(\"span\", id=\"visitDateVal\").get_text(strip=True)\n",
    "        reasons_for_visit = soup.find(\"span\", id=\"visitReasonVal\").get_text(strip=True)\n",
    " \n",
    "        # Define sections with start and end labels\n",
    "        sections = {\n",
    "            \"Allergies as of Visit Date\": (\"Allergies as of visit date\", \"Special Considerations\"),\n",
    "            \"Special Considerations\": (\"Special Considerations\", \"GYN Dx\"),\n",
    "            \"GYN Dx\": (\"GYN Dx\", \"Hem/Onc Diagnosis\"),\n",
    "            \"Hem/Onc Diagnosis\": (\"Hem/Onc Diagnosis\", \"H&P\"),\n",
    "            \"H&P\": (\"H&P\", \"Signs\"),\n",
    "            \"Signs\": (\"Signs\", \"Laboratory\"),\n",
    "            \"Laboratory\": (\"Laboratory\", \"Outside Rx\"),\n",
    "            \"Outside Rx\": (\"Outside Rx\", \"Medications\"),\n",
    "            \"Medications\": (\"Medications\", \"Therapy note\"),\n",
    "            \"Therapy note\": (\"Therapy note\", \"Diagnostic Imaging\"),\n",
    "            \"Diagnostic Imaging\": (\"Diagnostic Imaging\", \"Plan\"),\n",
    "            \"Plan\": (\"Plan\", \"Text Note\"),\n",
    "            \"Text Note\": (\"Text Note\", None)  # No end tag after 'Text Note'\n",
    "        }\n",
    " \n",
    "        # Dictionary to hold extracted section texts\n",
    "        section_data = {}\n",
    " \n",
    "        # Loop over the defined sections\n",
    "        for section_name, (start_label, end_label) in sections.items():\n",
    "            start_section = soup.find(\"span\", string=re.compile(re.escape(start_label)))\n",
    "            end_section = soup.find(\"span\", string=re.compile(re.escape(end_label))) if end_label else None\n",
    "            # Extract text between the start and end sections\n",
    "            section_text = \"\"\n",
    "            if start_section:\n",
    "                current_element = start_section.find_next(\"div\")\n",
    "                while current_element and current_element != end_section:\n",
    "                    section_text += current_element.get_text(\" \", strip=True)\n",
    "                    current_element = current_element.find_next_sibling()\n",
    "            section_data[section_name] = section_text if section_text else \"Not Found\"\n",
    "        # Append the data to the list\n",
    "        data_list.append({\n",
    "            \"Patient\": patient,\n",
    "            \"Location\": location,\n",
    "            \"DOB\": dob,\n",
    "            \"Attending Physician\": attending_physician,\n",
    "            \"MRN\": mrn,\n",
    "            \"Date\": date,\n",
    "            \"Reasons for Visit\": reasons_for_visit,\n",
    "            **section_data  # Expand the section data into columns\n",
    "        })\n",
    " \n",
    "# Convert the list of data to a DataFrame\n",
    "df = pd.DataFrame(data_list)\n",
    " \n",
    "# Preview the DataFrame to verify the results\n",
    "print(\"DataFrame preview:\")\n",
    "print(df)\n",
    " \n",
    "# Save the DataFrame to an Excel file\n",
    "#output_path = \"D:/HTML_Files_Ext/patient_data_combined_with_all_sections2.xlsx\"\n",
    "#df.to_excel(output_path, index=False)\n",
    "#print(f\"Data has been saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16f885b5-941e-4880-948b-6f25877939ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame preview:\n",
      "           Patient                                   Location         DOB  \\\n",
      "0  YVETTE A. LOPEZ  GYN-Medical Center San Antonio (Inactive)  09/16/1963   \n",
      "1  YVETTE A. LOPEZ  GYN-Medical Center San Antonio (Inactive)  09/16/1963   \n",
      "\n",
      "          Attending Physician       MRN        Date Reasons for Visit  \\\n",
      "0  Antonio Santillan-Gomez MD  02008593  06/28/2016  FLWP ( 4 MO FU )   \n",
      "1  Antonio Santillan-Gomez MD  02008593  10/06/2016        Data entry   \n",
      "\n",
      "                          Allergies as of visit date  \n",
      "0  {\"Allergies as of Visit Date\": \"Vicodin, po so...  \n",
      "1  {\"Allergies as of Visit Date\": \"Vicodin, po so...  \n",
      "Data has been saved to D:/HTML_Files_Ext/patient_data_combined_with_json_sections5.xlsx\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Directory containing the files\n",
    "directory_path = \"D:/HTML_Files_Ext\"\n",
    "\n",
    "# List to store data from each HTML file\n",
    "data_list = []\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    # Check if the file has an .html extension\n",
    "    if filename.endswith(\".html\"):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        # Load and parse the HTML file\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            html_content = file.read()\n",
    "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "        # Extract required fields\n",
    "        patient = soup.find(\"div\", id=\"patName\").get_text(strip=True).replace(\"Patient: \", \"\")\n",
    "        location = soup.find(\"span\", id=\"locNameVal\").get_text(strip=True)\n",
    "        dob = soup.find(\"span\", id=\"dobVal\").get_text(strip=True)\n",
    "        attending_physician = soup.find(\"span\", id=\"attendingVal\").get_text(strip=True)\n",
    "        mrn = soup.find(\"span\", id=\"mrnVal\").get_text(strip=True)\n",
    "        date = soup.find(\"span\", id=\"visitDateVal\").get_text(strip=True)\n",
    "        reasons_for_visit = soup.find(\"span\", id=\"visitReasonVal\").get_text(strip=True)\n",
    "        \n",
    "        # Dictionary to hold data before JSON conversion\n",
    "        data_dict = {\n",
    "            \"Patient\": patient,\n",
    "            \"Location\": location,\n",
    "            \"DOB\": dob,\n",
    "            \"Attending Physician\": attending_physician,\n",
    "            \"MRN\": mrn,\n",
    "            \"Date\": date,\n",
    "            \"Reasons for Visit\": reasons_for_visit\n",
    "        }\n",
    "        \n",
    "        # Define sections starting from 'Allergies as of Visit Date'\n",
    "        start_label = \"Allergies as of Visit Date\"\n",
    "        sections = {\n",
    "            \"Allergies as of Visit Date\": (\"Allergies as of visit date\", \"Special Considerations\"),\n",
    "            \"Special Considerations\": (\"Special Considerations\", \"GYN Dx\"),\n",
    "            \"GYN Dx\": (\"GYN Dx\", \"Hem/Onc Diagnosis\"),\n",
    "            \"Hem/Onc Diagnosis\": (\"Hem/Onc Diagnosis\", \"H&P\"),\n",
    "            \"H&P\": (\"H&P\", \"Signs\"),\n",
    "            \"Signs\": (\"Signs\", \"Laboratory\"),\n",
    "            \"Laboratory\": (\"Laboratory\", \"Outside Rx\"),\n",
    "            \"Outside Rx\": (\"Outside Rx\", \"Medications\"),\n",
    "            \"Medications\": (\"Medications\", \"Therapy note\"),\n",
    "            \"Therapy note\": (\"Therapy note\", \"Diagnostic Imaging\"),\n",
    "            \"Diagnostic Imaging\": (\"Diagnostic Imaging\", \"Plan\"),\n",
    "            \"Plan\": (\"Plan\", \"Text Note\"),\n",
    "            \"Text Note\": (\"Text Note\", None)  # No end tag after 'Text Note'\n",
    "        }\n",
    "        \n",
    "        # Dictionary to hold extracted section texts\n",
    "        section_data = {}\n",
    "        capture_data = False\n",
    "        \n",
    "        # Loop over the defined sections\n",
    "        for section_name, (start_label, end_label) in sections.items():\n",
    "            if start_label == \"Allergies as of visit date\":\n",
    "                capture_data = True  # Start capturing from \"Allergies as of Visit Date\"\n",
    "\n",
    "            if capture_data:\n",
    "                start_section = soup.find(\"span\", string=re.compile(re.escape(start_label)))\n",
    "                end_section = soup.find(\"span\", string=re.compile(re.escape(end_label))) if end_label else None\n",
    "                # Extract text between the start and end sections\n",
    "                section_text = \"\"\n",
    "                if start_section:\n",
    "                    current_element = start_section.find_next(\"div\")\n",
    "                    while current_element and current_element != end_section:\n",
    "                        section_text += current_element.get_text(\" \", strip=True)\n",
    "                        current_element = current_element.find_next_sibling()\n",
    "                section_data[section_name] = section_text if section_text else \"Not Found\"\n",
    "\n",
    "        # Convert section data to JSON and add to the dictionary\n",
    "        data_dict[\"Allergies as of visit date(Json)\"] = json.dumps(section_data)\n",
    "\n",
    "        # Append the data to the list\n",
    "        data_list.append(data_dict)\n",
    "\n",
    "# Convert the list of data to a DataFrame\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Preview the DataFrame to verify the results\n",
    "print(\"DataFrame preview:\")\n",
    "print(df)\n",
    "\n",
    "# Save the DataFrame to an Excel file (uncomment when saving)\n",
    "output_path = \"D:/HTML_Files_Ext/patient_data_combined_with_json_sections5.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(f\"Data has been saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c283dc5-3424-4598-be74-10a66db1cc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame preview:\n",
      "           Patient                                   Location         DOB  \\\n",
      "0  YVETTE A. LOPEZ  GYN-Medical Center San Antonio (Inactive)  09/16/1963   \n",
      "1  YVETTE A. LOPEZ  GYN-Medical Center San Antonio (Inactive)  09/16/1963   \n",
      "\n",
      "          Attending Physician       MRN        Date Reasons for Visit  \\\n",
      "0  Antonio Santillan-Gomez MD  02008593  06/28/2016  FLWP ( 4 MO FU )   \n",
      "1  Antonio Santillan-Gomez MD  02008593  10/06/2016        Data entry   \n",
      "\n",
      "                                           File_Path  \\\n",
      "0  D:/HTML_Files_Ext\\0_20160628-131141_GYNMedical...   \n",
      "1  D:/HTML_Files_Ext\\0_20161006-090033_GYNMedical...   \n",
      "\n",
      "                                           File_Name       Execution_Date  \\\n",
      "0  0_20160628-131141_GYNMedicalCenterSanAntonioIn...  2024-10-28 03:10:04   \n",
      "1  0_20161006-090033_GYNMedicalCenterSanAntonioIn...  2024-10-28 03:10:04   \n",
      "\n",
      "                    Allergies as of visit date(Json)  \n",
      "0  {\"Allergies as of Visit Date\": \"Vicodin, po so...  \n",
      "1  {\"Allergies as of Visit Date\": \"Vicodin, po so...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Directory containing the files\n",
    "directory_path = \"D:/HTML_Files_Ext\"\n",
    "\n",
    "# List to store data from each HTML file\n",
    "data_list = []\n",
    "\n",
    "# Get the current execution date\n",
    "execution_date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    # Check if the file has an .html extension\n",
    "    if filename.endswith(\".html\"):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        # Load and parse the HTML file\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            html_content = file.read()\n",
    "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "        # Extract required fields\n",
    "        patient = soup.find(\"div\", id=\"patName\").get_text(strip=True).replace(\"Patient: \", \"\")\n",
    "        location = soup.find(\"span\", id=\"locNameVal\").get_text(strip=True)\n",
    "        dob = soup.find(\"span\", id=\"dobVal\").get_text(strip=True)\n",
    "        attending_physician = soup.find(\"span\", id=\"attendingVal\").get_text(strip=True)\n",
    "        mrn = soup.find(\"span\", id=\"mrnVal\").get_text(strip=True)\n",
    "        date = soup.find(\"span\", id=\"visitDateVal\").get_text(strip=True)\n",
    "        reasons_for_visit = soup.find(\"span\", id=\"visitReasonVal\").get_text(strip=True)\n",
    "        \n",
    "        # Dictionary to hold data before JSON conversion\n",
    "        data_dict = {\n",
    "            \"Patient\": patient,\n",
    "            \"Location\": location,\n",
    "            \"DOB\": dob,\n",
    "            \"Attending Physician\": attending_physician,\n",
    "            \"MRN\": mrn,\n",
    "            \"Date\": date,\n",
    "            \"Reasons for Visit\": reasons_for_visit,\n",
    "            \"File_Path\": file_path,  # Add the file path\n",
    "            \"File_Name\": filename,    # Add the file name\n",
    "            \"Execution_Date\": execution_date  # Add execution date\n",
    "        }\n",
    "        \n",
    "        # Define sections starting from 'Allergies as of Visit Date'\n",
    "        start_label = \"Allergies as of Visit Date\"\n",
    "        sections = {\n",
    "            \"Allergies as of Visit Date\": (\"Allergies as of visit date\", \"Special Considerations\"),\n",
    "            \"Special Considerations\": (\"Special Considerations\", \"GYN Dx\"),\n",
    "            \"GYN Dx\": (\"GYN Dx\", \"Hem/Onc Diagnosis\"),\n",
    "            \"Hem/Onc Diagnosis\": (\"Hem/Onc Diagnosis\", \"H&P\"),\n",
    "            \"H&P\": (\"H&P\", \"Signs\"),\n",
    "            \"Signs\": (\"Signs\", \"Laboratory\"),\n",
    "            \"Laboratory\": (\"Laboratory\", \"Outside Rx\"),\n",
    "            \"Outside Rx\": (\"Outside Rx\", \"Medications\"),\n",
    "            \"Medications\": (\"Medications\", \"Therapy note\"),\n",
    "            \"Therapy note\": (\"Therapy note\", \"Diagnostic Imaging\"),\n",
    "            \"Diagnostic Imaging\": (\"Diagnostic Imaging\", \"Plan\"),\n",
    "            \"Plan\": (\"Plan\", \"Text Note\"),\n",
    "            \"Text Note\": (\"Text Note\", None)  # No end tag after 'Text Note'\n",
    "        }\n",
    "        \n",
    "        # Dictionary to hold extracted section texts\n",
    "        section_data = {}\n",
    "        capture_data = False\n",
    "        \n",
    "        # Loop over the defined sections\n",
    "        for section_name, (start_label, end_label) in sections.items():\n",
    "            if start_label == \"Allergies as of visit date\":\n",
    "                capture_data = True  # Start capturing from \"Allergies as of Visit Date\"\n",
    "\n",
    "            if capture_data:\n",
    "                start_section = soup.find(\"span\", string=re.compile(re.escape(start_label)))\n",
    "                end_section = soup.find(\"span\", string=re.compile(re.escape(end_label))) if end_label else None\n",
    "                # Extract text between the start and end sections\n",
    "                section_text = \"\"\n",
    "                if start_section:\n",
    "                    current_element = start_section.find_next(\"div\")\n",
    "                    while current_element and current_element != end_section:\n",
    "                        section_text += current_element.get_text(\" \", strip=True)\n",
    "                        current_element = current_element.find_next_sibling()\n",
    "                section_data[section_name] = section_text if section_text else \"Not Found\"\n",
    "\n",
    "        # Convert section data to JSON and add to the dictionary\n",
    "        data_dict[\"Allergies as of visit date(Json)\"] = json.dumps(section_data)\n",
    "\n",
    "        # Append the data to the list\n",
    "        data_list.append(data_dict)\n",
    "\n",
    "# Convert the list of data to a DataFrame\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Preview the DataFrame to verify the results\n",
    "print(\"DataFrame preview:\")\n",
    "print(df)\n",
    "\n",
    "# Save the DataFrame to an Excel file (uncomment when saving)\n",
    "output_path = \"D:/HTML_Files_Ext/patient_data_combined_with_json_sections6.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(f\"Data has been saved to {output_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d71d076-3e8f-4118-b6f9-482596b768da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML file successfully created at D:\\HTML_Files_Ext\\Bin_HTML_output_files\\lob1730502600014505286.html\n"
     ]
    }
   ],
   "source": [
    "# Path to the .bin file\n",
    "bin_file_path = r\"D:\\HTML_Files_Ext\\lob1730502600014505286.bin\"\n",
    "html_output_path = r\"D:\\HTML_Files_Ext\\Bin_HTML_output_files\\lob1730502600014505286.html\"\n",
    "\n",
    "# Open the binary file and read its content\n",
    "try:\n",
    "    with open(bin_file_path, \"rb\") as bin_file:\n",
    "        # Read the content of the bin file\n",
    "        bin_data = bin_file.read()\n",
    "\n",
    "    # Attempt to decode the binary data to text (using utf-8 or other encoding if necessary)\n",
    "    try:\n",
    "        decoded_text = bin_data.decode(\"utf-8\")  # Adjust the encoding if needed\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"Error: Could not decode binary data using utf-8.\")\n",
    "        decoded_text = bin_data.decode(\"latin-1\")  # You may try a different encoding here\n",
    "\n",
    "    # Write the decoded text into an HTML file\n",
    "    with open(html_output_path, \"w\", encoding=\"utf-8\") as html_file:\n",
    "        html_file.write(decoded_text)\n",
    "\n",
    "    print(f\"HTML file successfully created at {html_output_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file at path {bin_file_path} was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c15bbf25-21e0-4a08-9d4e-ec8886015b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown file format for lob1034411577975205166.bin. Skipping...\n",
      "Unknown file format for lob10501467738322404766.bin. Skipping...\n",
      "Unknown file format for lob10626829518212944619.bin. Skipping...\n",
      "Unknown file format for lob107031334653987491.bin. Skipping...\n",
      "Unknown file format for lob1077708249107881611.bin. Skipping...\n",
      "Unknown file format for lob1094213002255894382.bin. Skipping...\n",
      "Unknown file format for lob11049748732235748120.bin. Skipping...\n",
      "Unknown file format for lob1107450906559733108.bin. Skipping...\n",
      "Unknown file format for lob11221047292668554672.bin. Skipping...\n",
      "Unknown file format for lob123045195900684474.bin. Skipping...\n",
      "Unknown file format for lob143826308596261948.bin. Skipping...\n",
      "Unknown file format for lob163976911685831059.bin. Skipping...\n",
      "Unknown file format for lob267180463724377215.bin. Skipping...\n",
      "Unknown file format for lob290305702767849286.bin. Skipping...\n",
      "Unknown file format for lob295016282863131491.bin. Skipping...\n",
      "Unknown file format for lob423583334110337441.bin. Skipping...\n",
      "Unknown file format for lob437226328331831881.bin. Skipping...\n",
      "Unknown file format for lob475047120777137714.bin. Skipping...\n",
      "Unknown file format for lob486976585980910882.bin. Skipping...\n",
      "Unknown file format for lob491171144471832397.bin. Skipping...\n",
      "Unknown file format for lob528415886745066331.bin. Skipping...\n",
      "Unknown file format for lob629571349819815121.bin. Skipping...\n",
      "Unknown file format for lob755402139980606625.bin. Skipping...\n",
      "Unknown file format for lob809895354702684626.bin. Skipping...\n",
      "Unknown file format for lob849763135076888738.bin. Skipping...\n",
      "Unknown file format for lob886379556580629412.bin. Skipping...\n",
      "Unknown file format for lob904784905650845911.bin. Skipping...\n",
      "Unknown file format for lob908952981419887804.bin. Skipping...\n",
      "Unknown file format for lob914303600643549382.bin. Skipping...\n",
      "Unknown file format for lob967925554043446921.bin. Skipping...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Path to the folder containing .bin files\n",
    "bin_folder_path = r\"D:\\Files_Extraction_py\\BIN\"\n",
    "html_output_folder = r\"D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\"\n",
    "pdf_output_folder = r\"D:\\Files_Extraction_py\\BIN_TO_PDF_output_files\"\n",
    "\n",
    "# Ensure output folders exist\n",
    "os.makedirs(html_output_folder, exist_ok=True)\n",
    "os.makedirs(pdf_output_folder, exist_ok=True)\n",
    "\n",
    "# Function to detect if the file is HTML or PDF\n",
    "def detect_file_type(bin_data):\n",
    "    # Check for HTML content (common HTML tags)\n",
    "    if b'<!DOCTYPE html>' in bin_data or b'<html' in bin_data:\n",
    "        return 'html'\n",
    "    # Check for PDF content (PDF files typically start with \"%PDF\")\n",
    "    elif bin_data[:4] == b'%PDF':\n",
    "        return 'pdf'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "# Loop through all .bin files in the folder\n",
    "for filename in os.listdir(bin_folder_path):\n",
    "    if filename.endswith(\".bin\"):\n",
    "        bin_file_path = os.path.join(bin_folder_path, filename)\n",
    "        \n",
    "        # Read the binary file\n",
    "        try:\n",
    "            with open(bin_file_path, \"rb\") as bin_file:\n",
    "                bin_data = bin_file.read()\n",
    "\n",
    "            # Detect file type\n",
    "            file_type = detect_file_type(bin_data)\n",
    "\n",
    "            if file_type == 'html':\n",
    "                # Decode binary data as HTML and save\n",
    "                html_output_path = os.path.join(html_output_folder, f\"{filename}.html\")\n",
    "                try:\n",
    "                    decoded_text = bin_data.decode(\"utf-8\")\n",
    "                except UnicodeDecodeError:\n",
    "                    decoded_text = bin_data.decode(\"latin-1\")  # Fallback decoding\n",
    "\n",
    "                # Write to HTML file\n",
    "                with open(html_output_path, \"w\", encoding=\"utf-8\") as html_file:\n",
    "                    html_file.write(decoded_text)\n",
    "                print(f\"HTML file successfully created: {html_output_path}\")\n",
    "\n",
    "            elif file_type == 'pdf':\n",
    "                # Write the binary data to a PDF file\n",
    "                pdf_output_path = os.path.join(pdf_output_folder, f\"{filename}.pdf\")\n",
    "                with open(pdf_output_path, \"wb\") as pdf_file:\n",
    "                    pdf_file.write(bin_data)\n",
    "                print(f\"PDF file successfully created: {pdf_output_path}\")\n",
    "\n",
    "            else:\n",
    "                print(f\"Unknown file format for {filename}. Skipping...\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: The file {filename} was not found.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing {filename}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28e39056-63e5-4bee-b4c4-4f384eb9db55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob1034411577975205166.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob10501467738322404766.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob10626829518212944619.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob107031334653987491.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob1077708249107881611.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob1094213002255894382.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob11049748732235748120.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob1107450906559733108.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob11221047292668554672.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob123045195900684474.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob143826308596261948.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob163976911685831059.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob267180463724377215.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob290305702767849286.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob295016282863131491.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob423583334110337441.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob437226328331831881.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob475047120777137714.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob486976585980910882.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob491171144471832397.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob528415886745066331.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob629571349819815121.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob755402139980606625.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob809895354702684626.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob849763135076888738.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob886379556580629412.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob904784905650845911.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob908952981419887804.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob914303600643549382.html\n",
      "HTML file successfully created at D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\\lob967925554043446921.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Path to the folder containing .bin files\n",
    "bin_folder_path = r\"D:\\Files_Extraction_py\\BIN\"\n",
    "html_output_folder = r\"D:\\Files_Extraction_py\\BIN_TO_HTML_output_files\"\n",
    "pdf_output_folder = r\"D:\\Files_Extraction_py\\BIN_TO_PDF_output_files\"\n",
    "\n",
    "# Create output directories if they do not exist\n",
    "os.makedirs(html_output_folder, exist_ok=True)\n",
    "os.makedirs(pdf_output_folder, exist_ok=True)\n",
    "\n",
    "# Loop through each .bin file in the specified folder\n",
    "for file_name in os.listdir(bin_folder_path):\n",
    "    if file_name.endswith(\".bin\"):\n",
    "        bin_file_path = os.path.join(bin_folder_path, file_name)\n",
    "        html_output_path = os.path.join(html_output_folder, f\"{os.path.splitext(file_name)[0]}.html\")\n",
    "        pdf_output_path = os.path.join(pdf_output_folder, f\"{os.path.splitext(file_name)[0]}.pdf\")\n",
    "\n",
    "        # Open the binary file and read its content\n",
    "        try:\n",
    "            with open(bin_file_path, \"rb\") as bin_file:\n",
    "                # Read the content of the bin file\n",
    "                bin_data = bin_file.read()\n",
    "\n",
    "            # Attempt to decode the binary data\n",
    "            try:\n",
    "                decoded_text = bin_data.decode(\"utf-8\")  # Try decoding as HTML first\n",
    "                # If decoding succeeds, save as an HTML file\n",
    "                with open(html_output_path, \"w\", encoding=\"utf-8\") as html_file:\n",
    "                    html_file.write(decoded_text)\n",
    "                print(f\"HTML file successfully created at {html_output_path}\")\n",
    "\n",
    "            except UnicodeDecodeError:\n",
    "                print(f\"Error: Could not decode binary data using utf-8 for {file_name}. Trying PDF.\")\n",
    "\n",
    "                # If decoding as HTML fails, assume it's a PDF and save it as is\n",
    "                with open(pdf_output_path, \"wb\") as pdf_file:\n",
    "                    pdf_file.write(bin_data)\n",
    "                print(f\"PDF file successfully created at {pdf_output_path}\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: The file at path {bin_file_path} was not found.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing {file_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79e568d8-b936-44e4-a625-09bdd8f9ce4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytesseractNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pdf2image\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting pillow\n",
      "  Downloading pillow-11.0.0-cp310-cp310-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\administrator\\anaconda3\\envs\\ext_project\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\administrator\\anaconda3\\envs\\ext_project\\lib\\site-packages (3.1.5)\n",
      "Collecting PyMuPDF\n",
      "  Downloading PyMuPDF-1.24.12-cp39-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\administrator\\anaconda3\\envs\\ext_project\\lib\\site-packages (from pytesseract) (24.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\administrator\\anaconda3\\envs\\ext_project\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\administrator\\anaconda3\\envs\\ext_project\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\administrator\\anaconda3\\envs\\ext_project\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\administrator\\anaconda3\\envs\\ext_project\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\administrator\\anaconda3\\envs\\ext_project\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\administrator\\anaconda3\\envs\\ext_project\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Downloading pillow-11.0.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.6/2.6 MB 37.2 MB/s eta 0:00:00\n",
      "Downloading PyMuPDF-1.24.12-cp39-abi3-win_amd64.whl (16.0 MB)\n",
      "   ---------------------------------------- 0.0/16.0 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 7.3/16.0 MB 37.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 16.0/16.0 MB 50.4 MB/s eta 0:00:00\n",
      "Installing collected packages: PyMuPDF, pillow, pytesseract, pdf2image\n",
      "Successfully installed PyMuPDF-1.24.12 pdf2image-1.17.0 pillow-11.0.0 pytesseract-0.3.13\n"
     ]
    }
   ],
   "source": [
    "pip install pytesseract pdf2image pillow pandas openpyxl PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37ffe0eb-1ede-4d70-8ff6-7ed668cafa3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in c:\\users\\administrator\\anaconda3\\envs\\ext_project\\lib\\site-packages (0.3.13)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\administrator\\anaconda3\\envs\\ext_project\\lib\\site-packages (from pytesseract) (24.1)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\administrator\\anaconda3\\envs\\ext_project\\lib\\site-packages (from pytesseract) (11.0.0)\n"
     ]
    }
   ],
   "source": [
    "pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dac0246-912f-47d6-8320-a201293ab81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in c:\\users\\administrator\\anaconda3\\envs\\ext_project\\lib\\site-packages (1.24.12)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install PyMuPDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6edf845f-f42c-4732-bfea-98762e6b7fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdf2image in c:\\users\\administrator\\anaconda3\\envs\\ext_project\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\administrator\\anaconda3\\envs\\ext_project\\lib\\site-packages (from pdf2image) (11.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14f95c71-4373-4805-be7f-a8d5b24d29bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while processing 0006086B.pdf: Unable to get page count. Is poppler installed and in PATH?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pytesseract\n",
    "import fitz  # PyMuPDF\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "# Set the path to the Tesseract executable if not added to the system PATH\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Path to the folder containing the PDF files\n",
    "pdf_folder_path = r\"D:\\Files_Extraction_py\\PDF\"\n",
    "output_folder_path = r\"D:\\Files_Extraction_py\\PDF_Text_Output\"\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "# Loop through each PDF file in the folder\n",
    "for file_name in os.listdir(pdf_folder_path):\n",
    "    if file_name.endswith(\".pdf\"):\n",
    "        pdf_file_path = os.path.join(pdf_folder_path, file_name)\n",
    "        output_text_file_path = os.path.join(output_folder_path, f\"{os.path.splitext(file_name)[0]}.txt\")\n",
    "\n",
    "        try:\n",
    "            # Open the PDF\n",
    "            pdf_document = fitz.open(pdf_file_path)\n",
    "\n",
    "            # Initialize an empty string to store the extracted text\n",
    "            full_text = \"\"\n",
    "\n",
    "            # Loop through each page in the PDF\n",
    "            for page_num in range(len(pdf_document)):\n",
    "                # Convert PDF page to an image using pdf2image\n",
    "                images = convert_from_path(pdf_file_path, first_page=page_num + 1, last_page=page_num + 1)\n",
    "                for image in images:\n",
    "                    # Perform OCR on the image\n",
    "                    text = pytesseract.image_to_string(image)\n",
    "                    full_text += f\"\\n\\nPage {page_num + 1}:\\n{text}\"\n",
    "\n",
    "            # Save the extracted text to a file\n",
    "            with open(output_text_file_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "                output_file.write(full_text)\n",
    "\n",
    "            print(f\"Text extracted and saved to {output_text_file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing {file_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42f4bffa-2df8-4dc7-9082-1696049b81de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text extracted from D:\\Files_Extraction_py\\PDF\\0006086B.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output\\0006086B.txt\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "\n",
    "# Specify the Tesseract-OCR path\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# Path to the folder containing PDF files\n",
    "pdf_folder_path = r\"D:\\Files_Extraction_py\\PDF\"\n",
    "poppler_path = r\"C:\\Poppler\\Release-24.08.0-0\\poppler-24.08.0\\Library\\bin\"\n",
    "\n",
    "# Path to store the extracted text from PDFs\n",
    "output_folder_path = r\"D:\\Files_Extraction_py\\PDF\\Text_Output\"\n",
    "\n",
    "if not os.path.exists(output_folder_path):\n",
    "    os.makedirs(output_folder_path)\n",
    "\n",
    "# Function to extract text from PDF images\n",
    "def extract_text_from_pdf(pdf_path, poppler_path, output_folder):\n",
    "    try:\n",
    "        images = convert_from_path(pdf_path, poppler_path=poppler_path)\n",
    "        extracted_text = \"\"\n",
    "        \n",
    "        for i, image in enumerate(images):\n",
    "            text = pytesseract.image_to_string(image)\n",
    "            extracted_text += text\n",
    "        \n",
    "        pdf_name = os.path.basename(pdf_path).replace('.pdf', '')\n",
    "        output_text_file = os.path.join(output_folder, f\"{pdf_name}.txt\")\n",
    "        with open(output_text_file, 'w', encoding='utf-8') as text_file:\n",
    "            text_file.write(extracted_text)\n",
    "        \n",
    "        print(f\"Text extracted from {pdf_path} and saved to {output_text_file}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {pdf_path}: {e}\")\n",
    "\n",
    "# Loop through all PDF files in the folder and process them\n",
    "for pdf_file in os.listdir(pdf_folder_path):\n",
    "    if pdf_file.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(pdf_folder_path, pdf_file)\n",
    "        extract_text_from_pdf(pdf_path, poppler_path, output_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a1f64a6-bc8c-4bdb-b233-e4206801f0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\00055501.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output\\00055501.txt\n",
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\00055881.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output\\00055881.txt\n",
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\00055882.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output\\00055882.txt\n",
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\0005619B.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output\\0005619B.txt\n",
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\0006086B.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output\\0006086B.txt\n",
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\00061493.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output\\00061493.txt\n",
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\0008127E.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output\\0008127E.txt\n",
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\0009458E.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output\\0009458E.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob10374361011888519676.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output\\lob10374361011888519676.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob10391442969921308407.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output\\lob10391442969921308407.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob10843779109856270645.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output\\lob10843779109856270645.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob10868430469700624929.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output\\lob10868430469700624929.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob11280232883194975612.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output\\lob11280232883194975612.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob1137277121772399709.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output\\lob1137277121772399709.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob11464694314664688191.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output\\lob11464694314664688191.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob11551047163961252953.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output\\lob11551047163961252953.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob218091133851470193.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output\\lob218091133851470193.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob223683635029688380.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output\\lob223683635029688380.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob497280292392830755.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output\\lob497280292392830755.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob891322787885000525.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output\\lob891322787885000525.txt\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "\n",
    "# Specify the Tesseract-OCR path\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# Path to the folder containing PDF files\n",
    "pdf_folder_path = r\"D:\\Files_Extraction_py\\PDF\\PDF files\"\n",
    "poppler_path = r\"C:\\Poppler\\Release-24.08.0-0\\poppler-24.08.0\\Library\\bin\"\n",
    "\n",
    "# Path to store the extracted text from PDFs\n",
    "output_folder_path = r\"D:\\Files_Extraction_py\\PDF\\Text_Output\"\n",
    "\n",
    "if not os.path.exists(output_folder_path):\n",
    "    os.makedirs(output_folder_path)\n",
    "\n",
    "# Function to extract text from image-based PDFs using OCR\n",
    "def extract_text_from_image_pdf(pdf_path, poppler_path, output_folder):\n",
    "    try:\n",
    "        images = convert_from_path(pdf_path, poppler_path=poppler_path)\n",
    "        extracted_text = \"\"\n",
    "        \n",
    "        for i, image in enumerate(images):\n",
    "            text = pytesseract.image_to_string(image)\n",
    "            extracted_text += text\n",
    "        \n",
    "        pdf_name = os.path.basename(pdf_path).replace('.pdf', '')\n",
    "        output_text_file = os.path.join(output_folder, f\"{pdf_name}.txt\")\n",
    "        with open(output_text_file, 'w', encoding='utf-8') as text_file:\n",
    "            text_file.write(extracted_text)\n",
    "        \n",
    "        print(f\"OCR text extracted from {pdf_path} and saved to {output_text_file}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {pdf_path} with OCR: {e}\")\n",
    "\n",
    "# Function to extract text from text-based PDFs\n",
    "def extract_text_from_text_pdf(pdf_path, output_folder):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        extracted_text = \"\"\n",
    "\n",
    "        for page_num in range(pdf_document.page_count):\n",
    "            page = pdf_document.load_page(page_num)\n",
    "            extracted_text += page.get_text(\"text\")\n",
    "        \n",
    "        pdf_name = os.path.basename(pdf_path).replace('.pdf', '')\n",
    "        output_text_file = os.path.join(output_folder, f\"{pdf_name}.txt\")\n",
    "        with open(output_text_file, 'w', encoding='utf-8') as text_file:\n",
    "            text_file.write(extracted_text)\n",
    "\n",
    "        print(f\"Text extracted from {pdf_path} and saved to {output_text_file}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {pdf_path} as a text PDF: {e}\")\n",
    "\n",
    "# Function to decide whether to use OCR or direct text extraction\n",
    "def process_pdf(pdf_path, poppler_path, output_folder):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "        # Check if the PDF has any text on the first page\n",
    "        first_page_text = pdf_document[0].get_text(\"text\")\n",
    "        \n",
    "        if first_page_text.strip():  # If there's text, treat as text-based PDF\n",
    "            extract_text_from_text_pdf(pdf_path, output_folder)\n",
    "        else:  # If no text is found, treat as image-based PDF\n",
    "            extract_text_from_image_pdf(pdf_path, poppler_path, output_folder)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while deciding how to process {pdf_path}: {e}\")\n",
    "\n",
    "# Loop through all PDF files in the folder and process them\n",
    "for pdf_file in os.listdir(pdf_folder_path):\n",
    "    if pdf_file.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(pdf_folder_path, pdf_file)\n",
    "        process_pdf(pdf_path, poppler_path, output_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6fccebd-d000-4afd-89bd-c68e01e7bb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\00055501.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\00055501.txt\n",
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\00055881.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\00055881.txt\n",
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\00055882.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\00055882.txt\n",
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\0005619B.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\0005619B.txt\n",
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\0006086B.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\0006086B.txt\n",
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\00061493.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\00061493.txt\n",
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\0008127E.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\0008127E.txt\n",
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\0009458E.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\0009458E.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob10374361011888519676.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\lob10374361011888519676.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob10391442969921308407.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\lob10391442969921308407.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob10843779109856270645.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\lob10843779109856270645.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob10868430469700624929.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\lob10868430469700624929.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob11280232883194975612.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\lob11280232883194975612.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob1137277121772399709.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\lob1137277121772399709.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob11464694314664688191.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\lob11464694314664688191.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob11551047163961252953.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\lob11551047163961252953.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob218091133851470193.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\lob218091133851470193.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob223683635029688380.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\lob223683635029688380.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob497280292392830755.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\lob497280292392830755.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob891322787885000525.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\lob891322787885000525.txt\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Specify the Tesseract-OCR path\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# Path to the folder containing PDF files\n",
    "pdf_folder_path = r\"D:\\Files_Extraction_py\\PDF\\PDF files\"\n",
    "poppler_path = r\"C:\\Poppler\\Release-24.08.0-0\\poppler-24.08.0\\Library\\bin\"\n",
    "\n",
    "# Path to store the extracted text from PDFs\n",
    "output_folder_path = r\"D:\\Files_Extraction_py\\PDF\\Text_Output1\"\n",
    "\n",
    "if not os.path.exists(output_folder_path):\n",
    "    os.makedirs(output_folder_path)\n",
    "\n",
    "# Function to format text after extraction to keep colon-aligned text in the same line and aligned vertically\n",
    "def format_text_colon_alignment(extracted_text):\n",
    "    # Use regex to ensure that text following a colon is on the same line\n",
    "    formatted_text = re.sub(r':\\s*\\n\\s*', ': ', extracted_text)\n",
    "    \n",
    "    # Split the text into lines\n",
    "    lines = formatted_text.splitlines()\n",
    "\n",
    "    # Align colons vertically by determining the maximum length before the colon\n",
    "    max_length = 0\n",
    "    for line in lines:\n",
    "        if ':' in line:\n",
    "            key_part = line.split(':')[0]\n",
    "            max_length = max(max_length, len(key_part))\n",
    "\n",
    "    # Adjust lines to ensure all colons are vertically aligned\n",
    "    aligned_text = \"\"\n",
    "    for line in lines:\n",
    "        if ':' in line:\n",
    "            key_part, value_part = line.split(':', 1)\n",
    "            # Add enough spaces to align the colons\n",
    "            aligned_line = f\"{key_part.ljust(max_length)} : {value_part.strip()}\"\n",
    "            aligned_text += aligned_line + \"\\n\"\n",
    "        else:\n",
    "            aligned_text += line + \"\\n\"\n",
    "    \n",
    "    return aligned_text\n",
    "\n",
    "# Function to extract text from image-based PDFs using OCR\n",
    "def extract_text_from_image_pdf(pdf_path, poppler_path, output_folder):\n",
    "    try:\n",
    "        images = convert_from_path(pdf_path, poppler_path=poppler_path)\n",
    "        extracted_text = \"\"\n",
    "        \n",
    "        for i, image in enumerate(images):\n",
    "            text = pytesseract.image_to_string(image)\n",
    "            extracted_text += text\n",
    "        \n",
    "        # Apply formatting for colon alignment\n",
    "        formatted_text = format_text_colon_alignment(extracted_text)\n",
    "        \n",
    "        pdf_name = os.path.basename(pdf_path).replace('.pdf', '')\n",
    "        output_text_file = os.path.join(output_folder, f\"{pdf_name}.txt\")\n",
    "        with open(output_text_file, 'w', encoding='utf-8') as text_file:\n",
    "            text_file.write(formatted_text)\n",
    "        \n",
    "        print(f\"OCR text extracted from {pdf_path} and saved to {output_text_file}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {pdf_path} with OCR: {e}\")\n",
    "\n",
    "# Function to extract text from text-based PDFs\n",
    "def extract_text_from_text_pdf(pdf_path, output_folder):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        extracted_text = \"\"\n",
    "\n",
    "        for page_num in range(pdf_document.page_count):\n",
    "            page = pdf_document.load_page(page_num)\n",
    "            extracted_text += page.get_text(\"text\")\n",
    "        \n",
    "        # Apply formatting for colon alignment\n",
    "        formatted_text = format_text_colon_alignment(extracted_text)\n",
    "        \n",
    "        pdf_name = os.path.basename(pdf_path).replace('.pdf', '')\n",
    "        output_text_file = os.path.join(output_folder, f\"{pdf_name}.txt\")\n",
    "        with open(output_text_file, 'w', encoding='utf-8') as text_file:\n",
    "            text_file.write(formatted_text)\n",
    "\n",
    "        print(f\"Text extracted from {pdf_path} and saved to {output_text_file}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {pdf_path} as a text PDF: {e}\")\n",
    "\n",
    "# Function to decide whether to use OCR or direct text extraction\n",
    "def process_pdf(pdf_path, poppler_path, output_folder):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "        # Check if the PDF has any text on the first page\n",
    "        first_page_text = pdf_document[0].get_text(\"text\")\n",
    "        \n",
    "        if first_page_text.strip():  # If there's text, treat as text-based PDF\n",
    "            extract_text_from_text_pdf(pdf_path, output_folder)\n",
    "        else:  # If no text is found, treat as image-based PDF\n",
    "            extract_text_from_image_pdf(pdf_path, poppler_path, output_folder)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while deciding how to process {pdf_path}: {e}\")\n",
    "\n",
    "# Loop through all PDF files in the folder and process them\n",
    "for pdf_file in os.listdir(pdf_folder_path):\n",
    "    if pdf_file.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(pdf_folder_path, pdf_file)\n",
    "        process_pdf(pdf_path, poppler_path, output_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "592178a5-4238-4930-a21b-34cd5c04cee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\00055501.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\00055501.txt\n",
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\00055881.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\00055881.txt\n",
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\00055882.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\00055882.txt\n",
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\0005619B.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\0005619B.txt\n",
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\0006086B.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\0006086B.txt\n",
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\00061493.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\00061493.txt\n",
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\0008127E.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\0008127E.txt\n",
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\0009458E.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\0009458E.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob10374361011888519676.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\lob10374361011888519676.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob10391442969921308407.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\lob10391442969921308407.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob10843779109856270645.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\lob10843779109856270645.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob10868430469700624929.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\lob10868430469700624929.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob11280232883194975612.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\lob11280232883194975612.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob1137277121772399709.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\lob1137277121772399709.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob11464694314664688191.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\lob11464694314664688191.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob11551047163961252953.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\lob11551047163961252953.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob218091133851470193.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\lob218091133851470193.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob223683635029688380.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\lob223683635029688380.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob497280292392830755.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\lob497280292392830755.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob891322787885000525.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output1\\lob891322787885000525.txt\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Specify the Tesseract-OCR path\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# Path to the folder containing PDF files\n",
    "pdf_folder_path = r\"D:\\Files_Extraction_py\\PDF\\PDF files\"\n",
    "poppler_path = r\"C:\\Poppler\\Release-24.08.0-0\\poppler-24.08.0\\Library\\bin\"\n",
    "\n",
    "# Path to store the extracted text from PDFs\n",
    "output_folder_path = r\"D:\\Files_Extraction_py\\PDF\\Text_Output1\"\n",
    "\n",
    "if not os.path.exists(output_folder_path):\n",
    "    os.makedirs(output_folder_path)\n",
    "\n",
    "# Function to format text after extraction to keep colon-aligned text in the same line and aligned vertically\n",
    "# Excludes timestamps in formats like hh:mm:ss or hh:mm from colon alignment\n",
    "def format_text_colon_alignment(extracted_text):\n",
    "    # Use regex to ensure that text following a colon is on the same line,\n",
    "    # but avoid altering timestamps like 12:30:00 or 12:30.\n",
    "    formatted_text = re.sub(r'(?<!\\d):\\s*\\n\\s*', ': ', extracted_text)\n",
    "    \n",
    "    # Split the text into lines\n",
    "    lines = formatted_text.splitlines()\n",
    "\n",
    "    # Align colons vertically by determining the maximum length before the colon,\n",
    "    # but skip lines with timestamps (e.g., hh:mm:ss or hh:mm)\n",
    "    max_length = 0\n",
    "    for line in lines:\n",
    "        if ':' in line and not re.search(r'\\b\\d{1,2}:\\d{2}(:\\d{2})?\\b', line):\n",
    "            key_part = line.split(':')[0]\n",
    "            max_length = max(max_length, len(key_part))\n",
    "\n",
    "    # Adjust lines to ensure all colons are vertically aligned\n",
    "    aligned_text = \"\"\n",
    "    for line in lines:\n",
    "        if ':' in line and not re.search(r'\\b\\d{1,2}:\\d{2}(:\\d{2})?\\b', line):\n",
    "            key_part, value_part = line.split(':', 1)\n",
    "            # Add enough spaces to align the colons\n",
    "            aligned_line = f\"{key_part.ljust(max_length)} : {value_part.strip()}\"\n",
    "            aligned_text += aligned_line + \"\\n\"\n",
    "        else:\n",
    "            aligned_text += line + \"\\n\"\n",
    "    \n",
    "    return aligned_text\n",
    "\n",
    "# Function to extract text from image-based PDFs using OCR\n",
    "def extract_text_from_image_pdf(pdf_path, poppler_path, output_folder):\n",
    "    try:\n",
    "        images = convert_from_path(pdf_path, poppler_path=poppler_path)\n",
    "        extracted_text = \"\"\n",
    "        \n",
    "        for i, image in enumerate(images):\n",
    "            text = pytesseract.image_to_string(image)\n",
    "            extracted_text += text\n",
    "        \n",
    "        # Apply formatting for colon alignment\n",
    "        formatted_text = format_text_colon_alignment(extracted_text)\n",
    "        \n",
    "        pdf_name = os.path.basename(pdf_path).replace('.pdf', '')\n",
    "        output_text_file = os.path.join(output_folder, f\"{pdf_name}.txt\")\n",
    "        with open(output_text_file, 'w', encoding='utf-8') as text_file:\n",
    "            text_file.write(formatted_text)\n",
    "        \n",
    "        print(f\"OCR text extracted from {pdf_path} and saved to {output_text_file}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {pdf_path} with OCR: {e}\")\n",
    "\n",
    "# Function to extract text from text-based PDFs\n",
    "def extract_text_from_text_pdf(pdf_path, output_folder):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        extracted_text = \"\"\n",
    "\n",
    "        for page_num in range(pdf_document.page_count):\n",
    "            page = pdf_document.load_page(page_num)\n",
    "            extracted_text += page.get_text(\"text\")\n",
    "        \n",
    "        # Apply formatting for colon alignment\n",
    "        formatted_text = format_text_colon_alignment(extracted_text)\n",
    "        \n",
    "        pdf_name = os.path.basename(pdf_path).replace('.pdf', '')\n",
    "        output_text_file = os.path.join(output_folder, f\"{pdf_name}.txt\")\n",
    "        with open(output_text_file, 'w', encoding='utf-8') as text_file:\n",
    "            text_file.write(formatted_text)\n",
    "\n",
    "        print(f\"Text extracted from {pdf_path} and saved to {output_text_file}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {pdf_path} as a text PDF: {e}\")\n",
    "\n",
    "# Function to decide whether to use OCR or direct text extraction\n",
    "def process_pdf(pdf_path, poppler_path, output_folder):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "        # Check if the PDF has any text on the first page\n",
    "        first_page_text = pdf_document[0].get_text(\"text\")\n",
    "        \n",
    "        if first_page_text.strip():  # If there's text, treat as text-based PDF\n",
    "            extract_text_from_text_pdf(pdf_path, output_folder)\n",
    "        else:  # If no text is found, treat as image-based PDF\n",
    "            extract_text_from_image_pdf(pdf_path, poppler_path, output_folder)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while deciding how to process {pdf_path}: {e}\")\n",
    "\n",
    "# Loop through all PDF files in the folder and process them\n",
    "for pdf_file in os.listdir(pdf_folder_path):\n",
    "    if pdf_file.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(pdf_folder_path, pdf_file)\n",
    "        process_pdf(pdf_path, poppler_path, output_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b9cd641-5880-4d4d-b6c0-37fa36eaa5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\00055501.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output2\\00055501.txt\n",
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\00055881.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output2\\00055881.txt\n",
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\00055882.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output2\\00055882.txt\n",
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\0005619B.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output2\\0005619B.txt\n",
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\0006086B.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output2\\0006086B.txt\n",
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\00061493.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output2\\00061493.txt\n",
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\0008127E.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output2\\0008127E.txt\n",
      "OCR text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\0009458E.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output2\\0009458E.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob10374361011888519676.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output2\\lob10374361011888519676.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob10391442969921308407.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output2\\lob10391442969921308407.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob10843779109856270645.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output2\\lob10843779109856270645.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob10868430469700624929.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output2\\lob10868430469700624929.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob11280232883194975612.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output2\\lob11280232883194975612.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob1137277121772399709.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output2\\lob1137277121772399709.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob11464694314664688191.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output2\\lob11464694314664688191.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob11551047163961252953.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output2\\lob11551047163961252953.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob218091133851470193.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output2\\lob218091133851470193.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob223683635029688380.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output2\\lob223683635029688380.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob497280292392830755.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output2\\lob497280292392830755.txt\n",
      "Text extracted from D:\\Files_Extraction_py\\PDF\\PDF files\\lob891322787885000525.pdf and saved to D:\\Files_Extraction_py\\PDF\\Text_Output2\\lob891322787885000525.txt\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Specify the Tesseract-OCR path\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# Path to the folder containing PDF files\n",
    "pdf_folder_path = r\"D:\\Files_Extraction_py\\PDF\\PDF files\"\n",
    "poppler_path = r\"C:\\Poppler\\Release-24.08.0-0\\poppler-24.08.0\\Library\\bin\"\n",
    "\n",
    "# Path to store the extracted text from PDFs\n",
    "output_folder_path = r\"D:\\Files_Extraction_py\\PDF\\Text_Output2\"\n",
    "\n",
    "if not os.path.exists(output_folder_path):\n",
    "    os.makedirs(output_folder_path)\n",
    "\n",
    "# Function to format text after extraction to keep colon-aligned text in the same line and aligned vertically\n",
    "# Excludes timestamps in formats like hh:mm:ss or hh:mm from colon alignment and handles multi-line values\n",
    "def format_text_colon_alignment(extracted_text):\n",
    "    # Use regex to ensure that text following a colon is on the same line,\n",
    "    # but avoid altering timestamps like 12:30:00 or 12:30.\n",
    "    formatted_text = re.sub(r'(?<!\\d):\\s*\\n\\s*', ': ', extracted_text)\n",
    "    \n",
    "    # Split the text into lines\n",
    "    lines = formatted_text.splitlines()\n",
    "\n",
    "    # Align colons vertically by determining the maximum length before the colon,\n",
    "    # but skip lines with timestamps (e.g., hh:mm:ss or hh:mm)\n",
    "    max_length = 0\n",
    "    for line in lines:\n",
    "        if ':' in line and not re.search(r'\\b\\d{1,2}:\\d{2}(:\\d{2})?\\b', line):\n",
    "            key_part = line.split(':')[0]\n",
    "            max_length = max(max_length, len(key_part))\n",
    "\n",
    "    # Adjust lines to ensure all colons are vertically aligned\n",
    "    aligned_text = \"\"\n",
    "    grouped_lines = []\n",
    "    current_group = []\n",
    "\n",
    "    # Detect groups of related lines (those without colons)\n",
    "    for line in lines:\n",
    "        if ':' in line and not re.search(r'\\b\\d{1,2}:\\d{2}(:\\d{2})?\\b', line):\n",
    "            # If current group has entries, append them to the grouped_lines before adding new key-value pair\n",
    "            if current_group:\n",
    "                grouped_lines.append(' '.join(current_group))\n",
    "                current_group = []\n",
    "\n",
    "            key_part, value_part = line.split(':', 1)\n",
    "            # Add enough spaces to align the colons\n",
    "            aligned_line = f\"{key_part.ljust(max_length)} : {value_part.strip()}\"\n",
    "            grouped_lines.append(aligned_line)\n",
    "        else:\n",
    "            # Accumulate multi-line values\n",
    "            current_group.append(line.strip())\n",
    "\n",
    "    # Append any remaining grouped lines\n",
    "    if current_group:\n",
    "        grouped_lines.append(' '.join(current_group))\n",
    "\n",
    "    aligned_text = \"\\n\".join(grouped_lines)\n",
    "    \n",
    "    return aligned_text\n",
    "\n",
    "# Function to extract text from image-based PDFs using OCR\n",
    "def extract_text_from_image_pdf(pdf_path, poppler_path, output_folder):\n",
    "    try:\n",
    "        images = convert_from_path(pdf_path, poppler_path=poppler_path)\n",
    "        extracted_text = \"\"\n",
    "        \n",
    "        for i, image in enumerate(images):\n",
    "            text = pytesseract.image_to_string(image)\n",
    "            extracted_text += text\n",
    "        \n",
    "        # Apply formatting for colon alignment\n",
    "        formatted_text = format_text_colon_alignment(extracted_text)\n",
    "        \n",
    "        pdf_name = os.path.basename(pdf_path).replace('.pdf', '')\n",
    "        output_text_file = os.path.join(output_folder, f\"{pdf_name}.txt\")\n",
    "        with open(output_text_file, 'w', encoding='utf-8') as text_file:\n",
    "            text_file.write(formatted_text)\n",
    "        \n",
    "        print(f\"OCR text extracted from {pdf_path} and saved to {output_text_file}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {pdf_path} with OCR: {e}\")\n",
    "\n",
    "# Function to extract text from text-based PDFs\n",
    "def extract_text_from_text_pdf(pdf_path, output_folder):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        extracted_text = \"\"\n",
    "\n",
    "        for page_num in range(pdf_document.page_count):\n",
    "            page = pdf_document.load_page(page_num)\n",
    "            extracted_text += page.get_text(\"text\")\n",
    "        \n",
    "        # Apply formatting for colon alignment\n",
    "        formatted_text = format_text_colon_alignment(extracted_text)\n",
    "        \n",
    "        pdf_name = os.path.basename(pdf_path).replace('.pdf', '')\n",
    "        output_text_file = os.path.join(output_folder, f\"{pdf_name}.txt\")\n",
    "        with open(output_text_file, 'w', encoding='utf-8') as text_file:\n",
    "            text_file.write(formatted_text)\n",
    "\n",
    "        print(f\"Text extracted from {pdf_path} and saved to {output_text_file}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {pdf_path} as a text PDF: {e}\")\n",
    "\n",
    "# Function to decide whether to use OCR or direct text extraction\n",
    "def process_pdf(pdf_path, poppler_path, output_folder):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "        # Check if the PDF has any text on the first page\n",
    "        first_page_text = pdf_document[0].get_text(\"text\")\n",
    "        \n",
    "        if first_page_text.strip():  # If there's text, treat as text-based PDF\n",
    "            extract_text_from_text_pdf(pdf_path, output_folder)\n",
    "        else:  # If no text is found, treat as image-based PDF\n",
    "            extract_text_from_image_pdf(pdf_path, poppler_path, output_folder)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while deciding how to process {pdf_path}: {e}\")\n",
    "\n",
    "# Loop through all PDF files in the folder and process them\n",
    "for pdf_file in os.listdir(pdf_folder_path):\n",
    "    if pdf_file.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(pdf_folder_path, pdf_file)\n",
    "        process_pdf(pdf_path, poppler_path, output_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a29561-55a2-4eba-8c39-a7039d802568",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
